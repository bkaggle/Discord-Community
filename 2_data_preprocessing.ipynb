{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ProBook\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ProBook\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import gensim\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix,hstack\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.path.abspath(os.path.join('.','data', 'spam_discord_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>AuthorID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Attachments</th>\n",
       "      <th>Reactions</th>\n",
       "      <th>Spam_or_Scam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support</td>\n",
       "      <td>30a9375c-708c-4c77-99d4-48a2af6d1316</td>\n",
       "      <td>nreeves</td>\n",
       "      <td>2024-02-15 16:17:46</td>\n",
       "      <td>Walk I paper suddenly still stop.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Announcements</td>\n",
       "      <td>12e7307c-df80-4557-97c4-9a9ca871a238</td>\n",
       "      <td>dmiller</td>\n",
       "      <td>2024-01-25 03:45:05</td>\n",
       "      <td>Voice television free building house step lose...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General</td>\n",
       "      <td>aa9b28af-3f66-4043-9158-54e2d8ac7b6c</td>\n",
       "      <td>jonathan76</td>\n",
       "      <td>2024-02-26 18:26:26</td>\n",
       "      <td>Movie fast cold reach field girl forward best ...</td>\n",
       "      <td>http://www.arroyo-smith.biz/</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support</td>\n",
       "      <td>33421fc7-17f6-45c0-a23d-39889e268b98</td>\n",
       "      <td>ygarner</td>\n",
       "      <td>2024-01-28 15:17:03</td>\n",
       "      <td>Color themselves.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support</td>\n",
       "      <td>e0a02c63-63b6-4db5-a2d7-8b80b19398ec</td>\n",
       "      <td>lawrencelong</td>\n",
       "      <td>2024-03-01 00:48:48</td>\n",
       "      <td>Heavy recognize sea trip fill safe former ques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Channel                              AuthorID        Author  \\\n",
       "0        Support  30a9375c-708c-4c77-99d4-48a2af6d1316       nreeves   \n",
       "1  Announcements  12e7307c-df80-4557-97c4-9a9ca871a238       dmiller   \n",
       "2        General  aa9b28af-3f66-4043-9158-54e2d8ac7b6c    jonathan76   \n",
       "3        Support  33421fc7-17f6-45c0-a23d-39889e268b98       ygarner   \n",
       "4        Support  e0a02c63-63b6-4db5-a2d7-8b80b19398ec  lawrencelong   \n",
       "\n",
       "                  Date                                            Content  \\\n",
       "0  2024-02-15 16:17:46                  Walk I paper suddenly still stop.   \n",
       "1  2024-01-25 03:45:05  Voice television free building house step lose...   \n",
       "2  2024-02-26 18:26:26  Movie fast cold reach field girl forward best ...   \n",
       "3  2024-01-28 15:17:03                                  Color themselves.   \n",
       "4  2024-03-01 00:48:48  Heavy recognize sea trip fill safe former ques...   \n",
       "\n",
       "                    Attachments  Reactions  Spam_or_Scam  \n",
       "0                           NaN          8             0  \n",
       "1                           NaN          6             0  \n",
       "2  http://www.arroyo-smith.biz/          7             0  \n",
       "3                           NaN          5             1  \n",
       "4                           NaN          9             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Channel       10000 non-null  object\n",
      " 1   AuthorID      10000 non-null  object\n",
      " 2   Author        10000 non-null  object\n",
      " 3   Date          10000 non-null  object\n",
      " 4   Content       10000 non-null  object\n",
      " 5   Attachments   5052 non-null   object\n",
      " 6   Reactions     10000 non-null  int64 \n",
      " 7   Spam_or_Scam  10000 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Spam_or_Scam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walk I paper suddenly still stop.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voice television free building house step lose...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie fast cold reach field girl forward best ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color themselves.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heavy recognize sea trip fill safe former ques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Spam_or_Scam\n",
       "0                  Walk I paper suddenly still stop.             0\n",
       "1  Voice television free building house step lose...             0\n",
       "2  Movie fast cold reach field girl forward best ...             0\n",
       "3                                  Color themselves.             1\n",
       "4  Heavy recognize sea trip fill safe former ques...             0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Content','Spam_or_Scam']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning,Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "class TextPreprocessor():\n",
    "  \n",
    "\n",
    "  def extract_email_ids(self,doc):\n",
    "    '''This functions extract the email ids and domain names in the email adderss and returns a list of preprocessed email ids'''\n",
    "    list_of_preproessed_emails = []\n",
    "    list_of_emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',doc)\n",
    "    doc = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\" \",doc)\n",
    "    for txt in list_of_emails:\n",
    "      email = re.split(\"[.]\",re.split(\"@\", txt)[1])\n",
    "      y=email.copy()\n",
    "      for i in email:\n",
    "        if i==\"com\" or len(i)<=2:\n",
    "          y.remove(i)\n",
    "      email = ' '.join([str(i) for i in y])\n",
    "      email = email.lower()\n",
    "      list_of_preproessed_emails.append(email)\n",
    "    list_of_preproessed_emails = \" \".join(list_of_preproessed_emails)\n",
    "    return list_of_preproessed_emails\n",
    "\n",
    "  def text_lowercase(self,doc):\n",
    "    ''' This function converts the text to lower case'''\n",
    "    return doc.lower()\n",
    "  def remove_digits(self, doc):\n",
    "    '''This function removes all the numbers'''\n",
    "    return re.sub('\\d', '', doc)\n",
    "\n",
    "  def remove_underscores(self, doc):\n",
    "    '''This function removes all the underscores'''\n",
    "    return re.sub(r'_', '', doc)\n",
    "\n",
    "  def remove_excess_whitespace(self, doc):\n",
    "    '''This function removes excess white spaces'''\n",
    "    return re.sub('\\s+', ' ', doc)\n",
    "\n",
    "  def remove_special_characters(self, doc):\n",
    "    '''This function removes all the special characters'''\n",
    "    return re.sub('\\W', ' ', doc)\n",
    "\n",
    "  def remove_within_brackets(self, doc):\n",
    "    '''This function removes all the content within brackets'''\n",
    "    text = re.sub(r'', '', doc)\n",
    "    text = re.sub(r'<[^()]*>', '', text)\n",
    "    return text\n",
    "  \n",
    "  def expand_words(self, phrase):\n",
    "    '''This function expands the short form words '''\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "  def remove_short_and_long_words(self, doc):\n",
    "\n",
    "    '''This function removes all the short(<2 letters) and long(>15 letters) words '''\n",
    "    words = doc.split()\n",
    "    word_list = []\n",
    "    for word in words:\n",
    "      if len(word) > 2 and len(word) < 15 :\n",
    "        word_list.append(word)\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "  def text_lematizer(self,doc):\n",
    "    '''This function lematize the words to its root words'''\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    doc = nlp(doc)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "  def clean_document(self,doc):\n",
    "    '''This function cleans the documents'''\n",
    "    doc = self.text_lowercase(doc)\n",
    "    ids = self.extract_email_ids(doc)\n",
    "    doc = self.remove_within_brackets(doc)\n",
    "    doc = self.expand_words(doc)\n",
    "    doc = self.remove_underscores(doc)\n",
    "    doc = self.remove_special_characters(doc)\n",
    "    doc = self.remove_digits(doc)\n",
    "    doc = self.remove_excess_whitespace(doc)\n",
    "    doc = self.remove_short_and_long_words(doc)\n",
    "    doc = self.text_lematizer(doc)\n",
    "    doc = ids+doc\n",
    "    return doc\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"Word Count\",\"Average Word length\",\"Topic 1\",\"Topic 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.extend([\"tfidf_d\"+str(i) for i in range(0,3286)])#column name for pandas dataframe\n",
    "col.extend([\"avg_wv_d\"+str(i) for i in range(0,300)])\n",
    "col.extend([\"tfidf_w2v_d\"+str(i) for i in range(0,300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [2:52:20<00:00,  1.03s/it]    \n"
     ]
    }
   ],
   "source": [
    "tp = TextPreprocessor()\n",
    "processed_text = []\n",
    "for i in tqdm(df['Content']):\n",
    "  processed_text.append(tp.clean_document(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Content</th>\n",
       "      <th>Spam_or_Scam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Walk I paper suddenly still stop.</td>\n",
       "      <td>0</td>\n",
       "      <td>walk paper suddenly still stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Voice television free building house step lose...</td>\n",
       "      <td>0</td>\n",
       "      <td>voice television free building house step lose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Movie fast cold reach field girl forward best ...</td>\n",
       "      <td>0</td>\n",
       "      <td>movie fast cold reach field girl forward good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Color themselves.</td>\n",
       "      <td>1</td>\n",
       "      <td>color themselves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Heavy recognize sea trip fill safe former ques...</td>\n",
       "      <td>0</td>\n",
       "      <td>heavy recognize sea trip fill safe former ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            Content  \\\n",
       "0           0                  Walk I paper suddenly still stop.   \n",
       "1           1  Voice television free building house step lose...   \n",
       "2           2  Movie fast cold reach field girl forward best ...   \n",
       "3           3                                  Color themselves.   \n",
       "4           4  Heavy recognize sea trip fill safe former ques...   \n",
       "\n",
       "   Spam_or_Scam                                         clean_text  \n",
       "0             0                     walk paper suddenly still stop  \n",
       "1             0  voice television free building house step lose...  \n",
       "2             0  movie fast cold reach field girl forward good ...  \n",
       "3             1                                   color themselves  \n",
       "4             0  heavy recognize sea trip fill safe former ques...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
